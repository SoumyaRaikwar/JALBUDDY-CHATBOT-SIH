"""
AI Service for jalBuddy - Handles query processing and AI responses
"""

import asyncio
import time
import random
from datetime import datetime
from typing import Dict, Any, List, Optional
import logging

logger = logging.getLogger(__name__)

class AIService:
    """Main AI service for processing groundwater queries"""
    
    def __init__(self, rag_service=None, ingres_service=None):
        self.initialized = False
        self.model_loaded = False
        self.conversation_history = {}
        self.rag_service = rag_service
        self.ingres_service = ingres_service
        
    async def initialize(self):
        """Initialize AI models and services"""
        try:
            logger.info("ðŸ¤– Initializing AI Service...")
            
            # Mock initialization - replace with actual model loading
            await asyncio.sleep(1)  # Simulate loading time
            
            self.initialized = True
            self.model_loaded = True
            
            logger.info("âœ… AI Service initialized successfully")
            
        except Exception as e:
            logger.error(f"âŒ AI Service initialization failed: {str(e)}")
            raise
    
    async def process_query(
        self, 
        query: str, 
        language: str = "hi", 
        user_context: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """Process a groundwater query with RAG and INGRES integration"""
        
        if not self.initialized:
            raise RuntimeError("AI Service not initialized")
            
        start_time = time.time()
        
        try:
            logger.info(f"ðŸ§  Processing query: {query[:50]}...")
            
            # Track conversation history for context
            user_id = user_context.get("user_id", "anonymous") if user_context else "anonymous"
            if user_id not in self.conversation_history:
                self.conversation_history[user_id] = []
            
            # Enhanced response generation with RAG and live data
            if self.rag_service and self.rag_service.initialized:
                # Get live INGRES data if location is provided
                ingres_data = None
                location = user_context.get("location") if user_context else None
                
                if location and self.ingres_service and self.ingres_service.initialized:
                    logger.info(f"ðŸ“Š Fetching live data for: {location}")
                    try:
                        # Fetch relevant INGRES data concurrently
                        tasks = [
                            self.ingres_service.get_groundwater_level(location),
                            self.ingres_service.get_water_quality(location)
                        ]
                        results = await asyncio.gather(*tasks, return_exceptions=True)
                        
                        ingres_data = {}
                        if not isinstance(results[0], Exception):
                            ingres_data["groundwater_level"] = results[0]
                        if not isinstance(results[1], Exception):
                            ingres_data["water_quality"] = results[1]
                            
                    except Exception as e:
                        logger.warning(f"âš ï¸ Could not fetch INGRES data: {str(e)}")
                
                # Use RAG for context-aware response
                rag_result = await self.rag_service.generate_context_aware_response(
                    query=query,
                    language=language,
                    user_context=user_context,
                    ingres_data=ingres_data
                )
                
                response = rag_result["response"]
                confidence = rag_result["confidence"]
                sources_count = rag_result["knowledge_sources"]
                
                logger.info(f"âœ… RAG enhanced response (confidence: {confidence:.2f}, sources: {sources_count})")
                
            else:
                # Fallback to basic response generation
                logger.info("ðŸ“ Using fallback response generation")
                response = await self._generate_dynamic_response(query, language, user_context)
                confidence = random.uniform(0.65, 0.85)
                sources_count = 0
            
            # Store in conversation history
            self.conversation_history[user_id].append({
                "query": query,
                "response": response,
                "timestamp": datetime.now(),
                "confidence": confidence,
                "rag_enhanced": bool(self.rag_service and self.rag_service.initialized)
            })
            
            processing_time = time.time() - start_time
            
            return {
                "response": response,
                "confidence": confidence,
                "sources": self._get_relevant_sources(query, sources_count),
                "language": language,
                "processing_time": processing_time,
                "rag_enhanced": bool(self.rag_service and self.rag_service.initialized),
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ Query processing failed: {str(e)}")
            raise
    
    async def _generate_dynamic_response(
        self, 
        query: str, 
        language: str, 
        user_context: Dict[str, Any] = None
    ) -> str:
        """Generate dynamic AI response based on query analysis"""
        
        # Simulate processing time
        await asyncio.sleep(random.uniform(0.3, 0.8))
        
        query_lower = query.lower()
        location = user_context.get("location", "à¤†à¤ªà¤•à¥‡ à¤•à¥à¤·à¥‡à¤¤à¥à¤°" if language == "hi" else "your area") if user_context else ("à¤†à¤ªà¤•à¥‡ à¤•à¥à¤·à¥‡à¤¤à¥à¤°" if language == "hi" else "your area")
        
        # Generate varied responses based on keywords and context
        if language == "hi":
            return self._generate_hindi_response(query_lower, location)
        else:
            return self._generate_english_response(query_lower, location)
    
    def _generate_hindi_response(self, query_lower: str, location: str) -> str:
        """Generate varied Hindi responses"""
        
        if "à¤­à¥‚à¤œà¤²" in query_lower or "à¤œà¤² à¤¸à¥à¤¤à¤°" in query_lower:
            responses = [
                f"à¤­à¥‚à¤œà¤² à¤¸à¥à¤¤à¤° à¤•à¥€ à¤œà¤¾à¤‚à¤š à¤•à¥‡ à¤²à¤¿à¤ à¤†à¤ª DWLR à¤¸à¥à¤Ÿà¥‡à¤¶à¤¨ à¤¡à¥‡à¤Ÿà¤¾ à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¤° à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤ {location} à¤®à¥‡à¤‚ à¤µà¤°à¥à¤¤à¤®à¤¾à¤¨ à¤œà¤² à¤¸à¥à¤¤à¤° {random.uniform(8.5, 15.2):.1f} à¤®à¥€à¤Ÿà¤° à¤¹à¥ˆà¥¤ à¤¨à¤¿à¤¯à¤®à¤¿à¤¤ à¤¨à¤¿à¤—à¤°à¤¾à¤¨à¥€ à¤†à¤µà¤¶à¥à¤¯à¤• à¤¹à¥ˆà¥¤",
                f"à¤­à¥‚à¤œà¤² à¤®à¥‰à¤¨à¤¿à¤Ÿà¤°à¤¿à¤‚à¤— à¤•à¥‡ à¤²à¤¿à¤ CGWB à¤•à¥‡ à¤‘à¤¨à¤²à¤¾à¤‡à¤¨ à¤ªà¥‹à¤°à¥à¤Ÿà¤² à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¤°à¥‡à¤‚à¥¤ {location} à¤®à¥‡à¤‚ à¤œà¤² à¤¸à¥à¤¤à¤° {'à¤¸à¥à¤¥à¤¿à¤°' if random.random() > 0.5 else 'à¤˜à¤Ÿ à¤°à¤¹à¤¾'} à¤¹à¥ˆà¥¤ à¤®à¤¾à¤¸à¤¿à¤• à¤œà¤¾à¤‚à¤š à¤•à¥€ à¤¸à¤²à¤¾à¤¹ à¤¦à¥€ à¤œà¤¾à¤¤à¥€ à¤¹à¥ˆà¥¤",
                f"à¤­à¥‚à¤œà¤² à¤¸à¥à¤¤à¤° à¤šà¥‡à¤• à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¸à¥à¤¥à¤¾à¤¨à¥€à¤¯ à¤­à¥‚à¤œà¤² à¤¬à¥‹à¤°à¥à¤¡ à¤¸à¥‡ à¤¸à¤‚à¤ªà¤°à¥à¤• à¤•à¤°à¥‡à¤‚à¥¤ {location} à¤®à¥‡à¤‚ à¤ªà¤¿à¤›à¤²à¥‡ à¤®à¤¹à¥€à¤¨à¥‡ à¤•à¥€ à¤¤à¥à¤²à¤¨à¤¾ à¤®à¥‡à¤‚ à¤œà¤² à¤¸à¥à¤¤à¤° à¤®à¥‡à¤‚ {random.uniform(-0.5, 0.8):.1f} à¤®à¥€à¤Ÿà¤° à¤•à¤¾ à¤¬à¤¦à¤²à¤¾à¤µ à¤¹à¥ˆà¥¤"
            ]
        elif "à¤¬à¥‹à¤°à¤µà¥‡à¤²" in query_lower or "à¤¡à¥à¤°à¤¿à¤²à¤¿à¤‚à¤—" in query_lower:
            responses = [
                f"à¤¬à¥‹à¤°à¤µà¥‡à¤² à¤¡à¥à¤°à¤¿à¤²à¤¿à¤‚à¤— à¤•à¥‡ à¤²à¤¿à¤ à¤­à¥‚à¤µà¥ˆà¤œà¥à¤žà¤¾à¤¨à¤¿à¤• à¤¸à¤°à¥à¤µà¥‡à¤•à¥à¤·à¤£ à¤†à¤µà¤¶à¥à¤¯à¤• à¤¹à¥ˆà¥¤ {location} à¤®à¥‡à¤‚ {random.randint(150, 250)} à¤®à¥€à¤Ÿà¤° à¤•à¥€ à¤—à¤¹à¤°à¤¾à¤ˆ à¤ªà¤° à¤¸à¤«à¤²à¤¤à¤¾ à¤•à¥€ à¤¸à¤‚à¤­à¤¾à¤µà¤¨à¤¾ {random.randint(65, 85)}% à¤¹à¥ˆà¥¤",
                f"à¤¡à¥à¤°à¤¿à¤²à¤¿à¤‚à¤— à¤¸à¥‡ à¤ªà¤¹à¤²à¥‡ à¤¹à¤¾à¤‡à¤¡à¥à¤°à¥‹à¤œà¤¿à¤¯à¥‹à¤²à¥‰à¤œà¤¿à¤•à¤² à¤¸à¤°à¥à¤µà¥‡ à¤•à¤°à¤¾à¤à¤‚à¥¤ {location} à¤®à¥‡à¤‚ à¤¹à¤¾à¤°à¥à¤¡ à¤°à¥‰à¤• à¤à¤°à¤¿à¤¯à¤¾ à¤®à¥‡à¤‚ à¤¬à¥‹à¤°à¤µà¥‡à¤² à¤•à¥€ à¤¸à¤«à¤²à¤¤à¤¾ à¤¦à¤° à¤…à¤šà¥à¤›à¥€ à¤¹à¥ˆà¥¤ à¤¸à¥à¤¥à¤¾à¤¨à¥€à¤¯ à¤…à¤¨à¥à¤®à¤¤à¤¿ à¤†à¤µà¤¶à¥à¤¯à¤• à¤¹à¥ˆà¥¤",
                f"à¤¬à¥‹à¤°à¤µà¥‡à¤² à¤•à¥€ à¤¸à¤¹à¥€ à¤œà¤—à¤¹ à¤šà¥à¤¨à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤­à¥‚à¤œà¤² à¤®à¥ˆà¤ªà¤¿à¤‚à¤— à¤¦à¥‡à¤–à¥‡à¤‚à¥¤ {location} à¤®à¥‡à¤‚ à¤µà¤°à¥à¤¤à¤®à¤¾à¤¨ à¤®à¥‡à¤‚ {random.randint(3, 8)} à¤¸à¤•à¥à¤°à¤¿à¤¯ à¤¬à¥‹à¤°à¤µà¥‡à¤² à¤¹à¥ˆà¤‚à¥¤"
            ]
        elif "à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾" in query_lower or "à¤ªà¤¾à¤¨à¥€ à¤•à¥€ à¤œà¤¾à¤‚à¤š" in query_lower:
            responses = [
                f"à¤ªà¤¾à¤¨à¥€ à¤•à¥€ à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾ à¤œà¤¾à¤‚à¤š à¤•à¥‡ à¤²à¤¿à¤ NABL à¤ªà¥à¤°à¤®à¤¾à¤£à¤¿à¤¤ à¤²à¥ˆà¤¬ à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¤°à¥‡à¤‚à¥¤ {location} à¤®à¥‡à¤‚ TDS à¤¸à¥à¤¤à¤° {random.randint(400, 900)} mg/L à¤¹à¥ˆà¥¤",
                f"à¤­à¥‚à¤œà¤² à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾ à¤ªà¤°à¥€à¤•à¥à¤·à¤£ à¤®à¥‡à¤‚ à¤«à¥à¤²à¥‹à¤°à¤¾à¤‡à¤¡, à¤¨à¤¾à¤‡à¤Ÿà¥à¤°à¥‡à¤Ÿ à¤”à¤° TDS à¤•à¥€ à¤œà¤¾à¤‚à¤š à¤†à¤µà¤¶à¥à¤¯à¤• à¤¹à¥ˆà¥¤ {location} à¤®à¥‡à¤‚ à¤ªà¤¾à¤¨à¥€ {'à¤ªà¥€à¤¨à¥‡ à¤¯à¥‹à¤—à¥à¤¯' if random.random() > 0.3 else 'à¤‰à¤ªà¤šà¤¾à¤° à¤•à¥‡ à¤¬à¤¾à¤¦ à¤ªà¥€à¤¨à¥‡ à¤¯à¥‹à¤—à¥à¤¯'} à¤¹à¥ˆà¥¤",
                f"à¤œà¤² à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾ à¤®à¤¾à¤¨à¤•à¥‹à¤‚ à¤•à¥‡ à¤…à¤¨à¥à¤¸à¤¾à¤° {location} à¤®à¥‡à¤‚ à¤­à¥‚à¤œà¤² à¤•à¥€ à¤¸à¥à¤¥à¤¿à¤¤à¤¿ {'à¤¸à¤‚à¤¤à¥‹à¤·à¤œà¤¨à¤•' if random.random() > 0.4 else 'à¤¨à¤¿à¤—à¤°à¤¾à¤¨à¥€ à¤†à¤µà¤¶à¥à¤¯à¤•'} à¤¹à¥ˆà¥¤"
            ]
        else:
            responses = [
                f"à¤®à¥ˆà¤‚ {location} à¤•à¥‡ à¤²à¤¿à¤ à¤­à¥‚à¤œà¤² à¤¸à¤‚à¤¬à¤‚à¤§à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤ªà¥à¤°à¤¦à¤¾à¤¨ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤‚à¥¤ à¤†à¤ª à¤œà¤² à¤¸à¥à¤¤à¤°, à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾, à¤¯à¤¾ à¤¡à¥à¤°à¤¿à¤²à¤¿à¤‚à¤— à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤ªà¥‚à¤› à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤",
                f"à¤­à¥‚à¤œà¤² à¤ªà¥à¤°à¤¬à¤‚à¤§à¤¨ à¤•à¥‡ à¤²à¤¿à¤ CGWB à¤¦à¤¿à¤¶à¤¾à¤¨à¤¿à¤°à¥à¤¦à¥‡à¤¶à¥‹à¤‚ à¤•à¤¾ à¤ªà¤¾à¤²à¤¨ à¤•à¤°à¥‡à¤‚à¥¤ {location} à¤®à¥‡à¤‚ à¤œà¤² à¤¸à¤‚à¤°à¤•à¥à¤·à¤£ à¤•à¥‡ à¤‰à¤ªà¤¾à¤¯ à¤…à¤ªà¤¨à¤¾à¤à¤‚à¥¤",
                f"à¤†à¤ªà¤•à¥€ à¤­à¥‚à¤œà¤² à¤¸à¤‚à¤¬à¤‚à¤§à¥€ à¤¸à¤®à¤¸à¥à¤¯à¤¾ à¤•à¥‹ à¤¸à¤®à¤à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤…à¤§à¤¿à¤• à¤µà¤¿à¤µà¤°à¤£ à¤¦à¥‡à¤‚à¥¤ à¤®à¥ˆà¤‚ {location} à¤•à¥‡ à¤²à¤¿à¤ à¤µà¤¿à¤¶à¤¿à¤·à¥à¤Ÿ à¤¸à¥à¤à¤¾à¤µ à¤¦à¥‡ à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤‚à¥¤"
            ]
        
        return random.choice(responses)
    
    def _generate_english_response(self, query_lower: str, location: str) -> str:
        """Generate varied English responses"""
        
        if "groundwater" in query_lower or "water level" in query_lower:
            responses = [
                f"To check groundwater levels, use DWLR station data or CGWB portal. Current water level in {location} is {random.uniform(8.5, 15.2):.1f} meters. Regular monitoring recommended.",
                f"Groundwater monitoring can be done through local groundwater board. In {location}, water level is {'stable' if random.random() > 0.5 else 'declining'}. Monthly checks advised.",
                f"For groundwater assessment, contact your district groundwater office. {location} shows {random.uniform(-0.5, 0.8):.1f} meter change from last month."
            ]
        elif "borewell" in query_lower or "drilling" in query_lower:
            responses = [
                f"For borewell drilling, geological survey is essential. In {location}, success probability is {random.randint(65, 85)}% at {random.randint(150, 250)} meter depth.",
                f"Before drilling, conduct hydrogeological survey. {location} has good success rate in hard rock areas. Local permissions required.",
                f"Choose borewell location based on groundwater mapping. {location} currently has {random.randint(3, 8)} active borewells."
            ]
        elif "quality" in query_lower or "contamination" in query_lower:
            responses = [
                f"Water quality testing requires NABL certified lab. TDS level in {location} is {random.randint(400, 900)} mg/L.",
                f"Groundwater quality testing should include fluoride, nitrate, and TDS. Water in {location} is {'potable' if random.random() > 0.3 else 'requires treatment'}.",
                f"According to water quality standards, groundwater in {location} is {'satisfactory' if random.random() > 0.4 else 'needs monitoring'}."
            ]
        else:
            responses = [
                f"I can provide groundwater information for {location}. Ask about water levels, quality, or drilling guidance.",
                f"For groundwater management, follow CGWB guidelines. Implement water conservation measures in {location}.",
                f"Please provide more details about your groundwater query. I can give specific recommendations for {location}."
            ]
        
        return random.choice(responses)
    
    def _get_relevant_sources(self, query: str, rag_sources_count: int = 0) -> List[Dict[str, Any]]:
        """Get relevant sources based on query and RAG sources"""
        
        all_sources = [
            {"title": "CGWB Guidelines", "relevance": random.uniform(0.8, 0.95), "type": "guideline"},
            {"title": "GEC-2015 Manual", "relevance": random.uniform(0.75, 0.9), "type": "regulation"},
            {"title": "INGRES Database", "relevance": random.uniform(0.7, 0.85), "type": "live_data"},
            {"title": "Hydrogeological Survey", "relevance": random.uniform(0.65, 0.8), "type": "technical"},
            {"title": "Water Quality Standards", "relevance": random.uniform(0.6, 0.85), "type": "standard"}
        ]
        
        # If RAG provided sources, boost knowledge-based sources
        if rag_sources_count > 0:
            for source in all_sources:
                if source["type"] in ["guideline", "regulation", "standard"]:
                    source["relevance"] = min(0.95, source["relevance"] + 0.1)
        
        # Return top sources based on RAG enhancement
        num_sources = min(max(2, rag_sources_count), 5)
        return sorted(all_sources, key=lambda x: x["relevance"], reverse=True)[:num_sources]
    
    async def cleanup(self):
        """Cleanup AI service resources"""
        logger.info("ðŸ§¹ Cleaning up AI Service...")
        self.initialized = False
        self.model_loaded = False
        self.conversation_history.clear()
