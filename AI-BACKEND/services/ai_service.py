"""
AI Service for jalBuddy - Handles query processing and AI responses
"""

import asyncio
import time
import random
from datetime import datetime
from typing import Dict, Any, List, Optional
import logging

logger = logging.getLogger(__name__)

class AIService:
    """Main AI service for processing groundwater queries"""
    
    def __init__(self, rag_service=None, ingres_service=None):
        self.initialized = False
        self.model_loaded = False
        self.conversation_history = {}
        self.rag_service = rag_service
        self.ingres_service = ingres_service
        
    async def initialize(self):
        """Initialize AI models and services"""
        try:
            logger.info("ЁЯдЦ Initializing AI Service...")
            
            # Mock initialization - replace with actual model loading
            await asyncio.sleep(1)  # Simulate loading time
            
            self.initialized = True
            self.model_loaded = True
            
            logger.info("тЬЕ AI Service initialized successfully")
            
        except Exception as e:
            logger.error(f"тЭМ AI Service initialization failed: {str(e)}")
            raise
    
    async def process_query(
        self, 
        query: str, 
        language: str = "hi", 
        user_context: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """Process a groundwater query with RAG and INGRES integration"""
        
        if not self.initialized:
            raise RuntimeError("AI Service not initialized")
            
        start_time = time.time()
        
        try:
            logger.info(f"ЁЯза Processing query: {query[:50]}...")
            
            # Track conversation history for context
            user_id = user_context.get("user_id", "anonymous") if user_context else "anonymous"
            if user_id not in self.conversation_history:
                self.conversation_history[user_id] = []
            
            # Enhanced response generation with RAG and live data
            if self.rag_service and self.rag_service.initialized:
                # Get live INGRES data if location is provided
                ingres_data = None
                location = user_context.get("location") if user_context else None
                
                if location and self.ingres_service and self.ingres_service.initialized:
                    logger.info(f"ЁЯУК Fetching live data for: {location}")
                    try:
                        # Fetch relevant INGRES data concurrently
                        tasks = [
                            self.ingres_service.get_groundwater_level(location),
                            self.ingres_service.get_water_quality(location)
                        ]
                        results = await asyncio.gather(*tasks, return_exceptions=True)
                        
                        ingres_data = {}
                        if not isinstance(results[0], Exception):
                            ingres_data["groundwater_level"] = results[0]
                        if not isinstance(results[1], Exception):
                            ingres_data["water_quality"] = results[1]
                            
                    except Exception as e:
                        logger.warning(f"тЪая╕П Could not fetch INGRES data: {str(e)}")
                
                # Use RAG for context-aware response
                rag_result = await self.rag_service.generate_context_aware_response(
                    query=query,
                    language=language,
                    user_context=user_context,
                    ingres_data=ingres_data
                )
                
                response = rag_result["response"]
                confidence = rag_result["confidence"]
                sources_count = rag_result["knowledge_sources"]
                
                logger.info(f"тЬЕ RAG enhanced response (confidence: {confidence:.2f}, sources: {sources_count})")
                
            else:
                # Fallback to basic response generation
                logger.info("ЁЯУЭ Using fallback response generation")
                response = await self._generate_dynamic_response(query, language, user_context)
                confidence = random.uniform(0.65, 0.85)
                sources_count = 0
            
            # Store in conversation history
            self.conversation_history[user_id].append({
                "query": query,
                "response": response,
                "timestamp": datetime.now(),
                "confidence": confidence,
                "rag_enhanced": bool(self.rag_service and self.rag_service.initialized)
            })
            
            processing_time = time.time() - start_time
            
            return {
                "response": response,
                "confidence": confidence,
                "sources": self._get_relevant_sources(query, sources_count),
                "language": language,
                "processing_time": processing_time,
                "rag_enhanced": bool(self.rag_service and self.rag_service.initialized),
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"тЭМ Query processing failed: {str(e)}")
            raise
    
    async def _generate_dynamic_response(
        self, 
        query: str, 
        language: str, 
        user_context: Dict[str, Any] = None
    ) -> str:
        """Generate dynamic AI response based on query analysis"""
        
        # Simulate processing time
        await asyncio.sleep(random.uniform(0.3, 0.8))
        
        query_lower = query.lower()
        location = user_context.get("location", "рдЖрдкрдХреЗ рдХреНрд╖реЗрддреНрд░" if language == "hi" else "your area") if user_context else ("рдЖрдкрдХреЗ рдХреНрд╖реЗрддреНрд░" if language == "hi" else "your area")
        
        # Generate varied responses based on keywords and context
        if language == "hi":
            return self._generate_hindi_response(query_lower, location)
        else:
            return self._generate_english_response(query_lower, location)
    
    def _generate_hindi_response(self, query_lower: str, location: str) -> str:
        """Generate varied Hindi responses"""
        
        if "рднреВрдЬрд▓" in query_lower or "рдЬрд▓ рд╕реНрддрд░" in query_lower:
            responses = [
                f"рднреВрдЬрд▓ рд╕реНрддрд░ рдХреА рдЬрд╛рдВрдЪ рдХреЗ рд▓рд┐рдП рдЖрдк DWLR рд╕реНрдЯреЗрд╢рди рдбреЗрдЯрд╛ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред {location} рдореЗрдВ рд╡рд░реНрддрдорд╛рди рдЬрд▓ рд╕реНрддрд░ {random.uniform(8.5, 15.2):.1f} рдореАрдЯрд░ рд╣реИред рдирд┐рдпрдорд┐рдд рдирд┐рдЧрд░рд╛рдиреА рдЖрд╡рд╢реНрдпрдХ рд╣реИред",
                f"рднреВрдЬрд▓ рдореЙрдирд┐рдЯрд░рд┐рдВрдЧ рдХреЗ рд▓рд┐рдП CGWB рдХреЗ рдСрдирд▓рд╛рдЗрди рдкреЛрд░реНрдЯрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред {location} рдореЗрдВ рдЬрд▓ рд╕реНрддрд░ {'рд╕реНрдерд┐рд░' if random.random() > 0.5 else 'рдШрдЯ рд░рд╣рд╛'} рд╣реИред рдорд╛рд╕рд┐рдХ рдЬрд╛рдВрдЪ рдХреА рд╕рд▓рд╛рд╣ рджреА рдЬрд╛рддреА рд╣реИред",
                f"рднреВрдЬрд▓ рд╕реНрддрд░ рдЪреЗрдХ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рд╕реНрдерд╛рдиреАрдп рднреВрдЬрд▓ рдмреЛрд░реНрдб рд╕реЗ рд╕рдВрдкрд░реНрдХ рдХрд░реЗрдВред {location} рдореЗрдВ рдкрд┐рдЫрд▓реЗ рдорд╣реАрдиреЗ рдХреА рддреБрд▓рдирд╛ рдореЗрдВ рдЬрд▓ рд╕реНрддрд░ рдореЗрдВ {random.uniform(-0.5, 0.8):.1f} рдореАрдЯрд░ рдХрд╛ рдмрджрд▓рд╛рд╡ рд╣реИред"
            ]
        elif "рдмреЛрд░рд╡реЗрд▓" in query_lower or "рдбреНрд░рд┐рд▓рд┐рдВрдЧ" in query_lower:
            responses = [
                f"рдмреЛрд░рд╡реЗрд▓ рдбреНрд░рд┐рд▓рд┐рдВрдЧ рдХреЗ рд▓рд┐рдП рднреВрд╡реИрдЬреНрдЮрд╛рдирд┐рдХ рд╕рд░реНрд╡реЗрдХреНрд╖рдг рдЖрд╡рд╢реНрдпрдХ рд╣реИред {location} рдореЗрдВ {random.randint(150, 250)} рдореАрдЯрд░ рдХреА рдЧрд╣рд░рд╛рдИ рдкрд░ рд╕рдлрд▓рддрд╛ рдХреА рд╕рдВрднрд╛рд╡рдирд╛ {random.randint(65, 85)}% рд╣реИред",
                f"рдбреНрд░рд┐рд▓рд┐рдВрдЧ рд╕реЗ рдкрд╣рд▓реЗ рд╣рд╛рдЗрдбреНрд░реЛрдЬрд┐рдпреЛрд▓реЙрдЬрд┐рдХрд▓ рд╕рд░реНрд╡реЗ рдХрд░рд╛рдПрдВред {location} рдореЗрдВ рд╣рд╛рд░реНрдб рд░реЙрдХ рдПрд░рд┐рдпрд╛ рдореЗрдВ рдмреЛрд░рд╡реЗрд▓ рдХреА рд╕рдлрд▓рддрд╛ рджрд░ рдЕрдЪреНрдЫреА рд╣реИред рд╕реНрдерд╛рдиреАрдп рдЕрдиреБрдорддрд┐ рдЖрд╡рд╢реНрдпрдХ рд╣реИред",
                f"рдмреЛрд░рд╡реЗрд▓ рдХреА рд╕рд╣реА рдЬрдЧрд╣ рдЪреБрдирдиреЗ рдХреЗ рд▓рд┐рдП рднреВрдЬрд▓ рдореИрдкрд┐рдВрдЧ рджреЗрдЦреЗрдВред {location} рдореЗрдВ рд╡рд░реНрддрдорд╛рди рдореЗрдВ {random.randint(3, 8)} рд╕рдХреНрд░рд┐рдп рдмреЛрд░рд╡реЗрд▓ рд╣реИрдВред"
            ]
        elif "рдЧреБрдгрд╡рддреНрддрд╛" in query_lower or "рдкрд╛рдиреА рдХреА рдЬрд╛рдВрдЪ" in query_lower:
            responses = [
                f"рдкрд╛рдиреА рдХреА рдЧреБрдгрд╡рддреНрддрд╛ рдЬрд╛рдВрдЪ рдХреЗ рд▓рд┐рдП NABL рдкреНрд░рдорд╛рдгрд┐рдд рд▓реИрдм рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред {location} рдореЗрдВ TDS рд╕реНрддрд░ {random.randint(400, 900)} mg/L рд╣реИред",
                f"рднреВрдЬрд▓ рдЧреБрдгрд╡рддреНрддрд╛ рдкрд░реАрдХреНрд╖рдг рдореЗрдВ рдлреНрд▓реЛрд░рд╛рдЗрдб, рдирд╛рдЗрдЯреНрд░реЗрдЯ рдФрд░ TDS рдХреА рдЬрд╛рдВрдЪ рдЖрд╡рд╢реНрдпрдХ рд╣реИред {location} рдореЗрдВ рдкрд╛рдиреА {'рдкреАрдиреЗ рдпреЛрдЧреНрдп' if random.random() > 0.3 else 'рдЙрдкрдЪрд╛рд░ рдХреЗ рдмрд╛рдж рдкреАрдиреЗ рдпреЛрдЧреНрдп'} рд╣реИред",
                f"рдЬрд▓ рдЧреБрдгрд╡рддреНрддрд╛ рдорд╛рдирдХреЛрдВ рдХреЗ рдЕрдиреБрд╕рд╛рд░ {location} рдореЗрдВ рднреВрдЬрд▓ рдХреА рд╕реНрдерд┐рддрд┐ {'рд╕рдВрддреЛрд╖рдЬрдирдХ' if random.random() > 0.4 else 'рдирд┐рдЧрд░рд╛рдиреА рдЖрд╡рд╢реНрдпрдХ'} рд╣реИред"
            ]
        else:
            responses = [
                f"рдореИрдВ {location} рдХреЗ рд▓рд┐рдП рднреВрдЬрд▓ рд╕рдВрдмрдВрдзреА рдЬрд╛рдирдХрд╛рд░реА рдкреНрд░рджрд╛рди рдХрд░ рд╕рдХрддрд╛ рд╣реВрдВред рдЖрдк рдЬрд▓ рд╕реНрддрд░, рдЧреБрдгрд╡рддреНрддрд╛, рдпрд╛ рдбреНрд░рд┐рд▓рд┐рдВрдЧ рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдкреВрдЫ рд╕рдХрддреЗ рд╣реИрдВред",
                f"рднреВрдЬрд▓ рдкреНрд░рдмрдВрдзрди рдХреЗ рд▓рд┐рдП CGWB рджрд┐рд╢рд╛рдирд┐рд░реНрджреЗрд╢реЛрдВ рдХрд╛ рдкрд╛рд▓рди рдХрд░реЗрдВред {location} рдореЗрдВ рдЬрд▓ рд╕рдВрд░рдХреНрд╖рдг рдХреЗ рдЙрдкрд╛рдп рдЕрдкрдирд╛рдПрдВред",
                f"рдЖрдкрдХреА рднреВрдЬрд▓ рд╕рдВрдмрдВрдзреА рд╕рдорд╕реНрдпрд╛ рдХреЛ рд╕рдордЭрдиреЗ рдХреЗ рд▓рд┐рдП рдЕрдзрд┐рдХ рд╡рд┐рд╡рд░рдг рджреЗрдВред рдореИрдВ {location} рдХреЗ рд▓рд┐рдП рд╡рд┐рд╢рд┐рд╖реНрдЯ рд╕реБрдЭрд╛рд╡ рджреЗ рд╕рдХрддрд╛ рд╣реВрдВред"
            ]
        
        return random.choice(responses)
    
    def _generate_english_response(self, query_lower: str, location: str) -> str:
        """Generate varied English responses"""
        
        if "groundwater" in query_lower or "water level" in query_lower:
            responses = [
                f"To check groundwater levels, use DWLR station data or CGWB portal. Current water level in {location} is {random.uniform(8.5, 15.2):.1f} meters. Regular monitoring recommended.",
                f"Groundwater monitoring can be done through local groundwater board. In {location}, water level is {'stable' if random.random() > 0.5 else 'declining'}. Monthly checks advised.",
                f"For groundwater assessment, contact your district groundwater office. {location} shows {random.uniform(-0.5, 0.8):.1f} meter change from last month."
            ]
        elif "borewell" in query_lower or "drilling" in query_lower:
            responses = [
                f"For borewell drilling, geological survey is essential. In {location}, success probability is {random.randint(65, 85)}% at {random.randint(150, 250)} meter depth.",
                f"Before drilling, conduct hydrogeological survey. {location} has good success rate in hard rock areas. Local permissions required.",
                f"Choose borewell location based on groundwater mapping. {location} currently has {random.randint(3, 8)} active borewells."
            ]
        elif "quality" in query_lower or "contamination" in query_lower:
            responses = [
                f"Water quality testing requires NABL certified lab. TDS level in {location} is {random.randint(400, 900)} mg/L.",
                f"Groundwater quality testing should include fluoride, nitrate, and TDS. Water in {location} is {'potable' if random.random() > 0.3 else 'requires treatment'}.",
                f"According to water quality standards, groundwater in {location} is {'satisfactory' if random.random() > 0.4 else 'needs monitoring'}."
            ]
        else:
            responses = [
                f"I can provide groundwater information for {location}. Ask about water levels, quality, or drilling guidance.",
                f"For groundwater management, follow CGWB guidelines. Implement water conservation measures in {location}.",
                f"Please provide more details about your groundwater query. I can give specific recommendations for {location}."
            ]
        
        return random.choice(responses)
    
    def _get_relevant_sources(self, query: str, rag_sources_count: int = 0) -> List[Dict[str, Any]]:
        """Get relevant sources based on query and RAG sources"""
        
        all_sources = [
            {"title": "CGWB Guidelines", "relevance": random.uniform(0.8, 0.95), "type": "guideline"},
            {"title": "GEC-2015 Manual", "relevance": random.uniform(0.75, 0.9), "type": "regulation"},
            {"title": "INGRES Database", "relevance": random.uniform(0.7, 0.85), "type": "live_data"},
            {"title": "Hydrogeological Survey", "relevance": random.uniform(0.65, 0.8), "type": "technical"},
            {"title": "Water Quality Standards", "relevance": random.uniform(0.6, 0.85), "type": "standard"}
        ]
        
        # If RAG provided sources, boost knowledge-based sources
        if rag_sources_count > 0:
            for source in all_sources:
                if source["type"] in ["guideline", "regulation", "standard"]:
                    source["relevance"] = min(0.95, source["relevance"] + 0.1)
        
        # Return top sources based on RAG enhancement
        num_sources = min(max(2, rag_sources_count), 5)
        return sorted(all_sources, key=lambda x: x["relevance"], reverse=True)[:num_sources]
    
    async def cleanup(self):
        """Cleanup AI service resources"""
        logger.info("ЁЯз╣ Cleaning up AI Service...")
        self.initialized = False
        self.model_loaded = False
        self.conversation_history.clear()
